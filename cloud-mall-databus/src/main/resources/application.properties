spring.application.name=cloud-mall-databus
server.port = 10100

spring.kafka.bootstrap-servers=192.168.3.101:9092,192.168.3.101:9092,192.168.3.103:9092
# 强一致性的情况下，生产者可以要求所有broker都响应才确保该条消息被成功写入
spring.kafka.producer.acks=-1
spring.kafka.producer.properties.producer.type=sync
# 对于消息没有顺序，可以设置重试参数；如果有顺序要求，这里应该设置为0，因为重试有可能造成消息顺序错乱
spring.kafka.producer.retries=3
# 每次尝试增加的额外的间隔时间,第一次1秒，第二次2秒，第三次3秒
spring.kafka.producer.properties.retry.backoff.ms=1000
# #当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
spring.kafka.producer.batch-size=16384
# 设置生产者内存缓冲区的大小：32M
spring.kafka.producer.buffer-memory=33554432
# spring.kafka.producer.compression-type=none
# 键的序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# 值的序列化方式
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer


# 禁止自动提交，有可能造成消息丢失
spring.kafka.consumer.enable-auto-commit=false
# key的反序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# value的反序列化方式
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.group-id=story-client
spring.kafka.listener.ack-mode=manual

#canal.zk-servers = 192.168.3.101:2181,192.168.3.102:2181,192.168.3.103:2181
canal.zk-servers =
canal.samples.host = 192.168.3.101
canal.samples.port = 11111
canal.samples.destination = samples
canal.samples.username = samples
canal.samples.password = samples
canal.samples.batch-size = 1000

canal.novel.host = 192.168.3.101
canal.novel.port = 11111
canal.novel.destination = novel
canal.novel.username = novel
canal.novel.password = novel
canal.novel.batch-size = 1000